{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pnandini-sdu/AAI-511-Final-Project/blob/main/FinalTeam_Project_AAI511_CNN_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pretty_midi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NO61mO7YcVq1",
        "outputId": "cfafeea0-8371-41dd-b744-406427f4aa8b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pretty_midi\n",
            "  Downloading pretty_midi-0.2.10.tar.gz (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from pretty_midi) (2.0.2)\n",
            "Collecting mido>=1.1.16 (from pretty_midi)\n",
            "  Downloading mido-1.3.3-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from pretty_midi) (1.17.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mido>=1.1.16->pretty_midi) (25.0)\n",
            "Downloading mido-1.3.3-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pretty_midi\n",
            "  Building wheel for pretty_midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretty_midi: filename=pretty_midi-0.2.10-py3-none-any.whl size=5592286 sha256=c7df02adc8452537bfc15a87086a0bb236be4cc8312b58475ba222c4ccd3a908\n",
            "  Stored in directory: /root/.cache/pip/wheels/e6/95/ac/15ceaeb2823b04d8e638fd1495357adb8d26c00ccac9d7782e\n",
            "Successfully built pretty_midi\n",
            "Installing collected packages: mido, pretty_midi\n",
            "Successfully installed mido-1.3.3 pretty_midi-0.2.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "en036vQ68_NP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "14469575-4d26-4b09-f37c-d00d0e02c2cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Pieces -> train: 1140, val: 245, test: 245\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Window counts per class: {'Beethoven': 15806, 'Mozart': 13972, 'Bach': 21660, 'Chopin': 4183}\n",
            "Class weights: {'Bach': 0.642, 'Beethoven': 0.88, 'Chopin': 3.324, 'Mozart': 0.995}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m76\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m76\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m76\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m76\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m9,248\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m76\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m61,504\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m172,160\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m147,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)     │       \u001b[38;5;34m295,168\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)     │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m516\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">76</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">76</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">76</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">76</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">76</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">61,504</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">172,160</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)     │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m741,220\u001b[0m (2.83 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">741,220</span> (2.83 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m739,556\u001b[0m (2.82 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">739,556</span> (2.82 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,664\u001b[0m (6.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,664</span> (6.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "   3477/Unknown \u001b[1m199s\u001b[0m 46ms/step - accuracy: 0.5164 - loss: 1.2112"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:160: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[warn] failed /content/drive/My Drive/music_dataset/Beethoven/Anhang 14-3.mid: Could not decode key with 3 flats and mode 255\n",
            "\u001b[1m3477/3477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 73ms/step - accuracy: 0.5164 - loss: 1.2112 - val_accuracy: 0.5894 - val_loss: 1.0033 - learning_rate: 4.0000e-04\n",
            "Epoch 2/40\n",
            "\u001b[1m3477/3477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6689 - loss: 0.7819[warn] failed /content/drive/My Drive/music_dataset/Beethoven/Anhang 14-3.mid: Could not decode key with 3 flats and mode 255\n",
            "\u001b[1m3477/3477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 53ms/step - accuracy: 0.6689 - loss: 0.7819 - val_accuracy: 0.5072 - val_loss: 1.2423 - learning_rate: 4.0000e-04\n",
            "Epoch 3/40\n",
            "\u001b[1m3474/3477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7151 - loss: 0.6797[warn] failed /content/drive/My Drive/music_dataset/Beethoven/Anhang 14-3.mid: Could not decode key with 3 flats and mode 255\n",
            "\u001b[1m3477/3477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 53ms/step - accuracy: 0.7151 - loss: 0.6796 - val_accuracy: 0.7343 - val_loss: 0.6599 - learning_rate: 4.0000e-04\n",
            "Epoch 4/40\n",
            "\u001b[1m3471/3477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7465 - loss: 0.6115[warn] failed /content/drive/My Drive/music_dataset/Beethoven/Anhang 14-3.mid: Could not decode key with 3 flats and mode 255\n",
            "\u001b[1m3477/3477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 53ms/step - accuracy: 0.7465 - loss: 0.6114 - val_accuracy: 0.7380 - val_loss: 0.6692 - learning_rate: 4.0000e-04\n",
            "Epoch 5/40\n",
            "\u001b[1m3477/3477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7665 - loss: 0.5673[warn] failed /content/drive/My Drive/music_dataset/Beethoven/Anhang 14-3.mid: Could not decode key with 3 flats and mode 255\n",
            "\u001b[1m3477/3477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 53ms/step - accuracy: 0.7665 - loss: 0.5673 - val_accuracy: 0.6937 - val_loss: 0.7571 - learning_rate: 4.0000e-04\n",
            "Epoch 6/40\n",
            "\u001b[1m3467/3477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7814 - loss: 0.5255[warn] failed /content/drive/My Drive/music_dataset/Beethoven/Anhang 14-3.mid: Could not decode key with 3 flats and mode 255\n",
            "\u001b[1m3477/3477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 53ms/step - accuracy: 0.7814 - loss: 0.5254 - val_accuracy: 0.6200 - val_loss: 1.0926 - learning_rate: 4.0000e-04\n",
            "Epoch 7/40\n",
            "\u001b[1m3474/3477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7942 - loss: 0.4959[warn] failed /content/drive/My Drive/music_dataset/Beethoven/Anhang 14-3.mid: Could not decode key with 3 flats and mode 255\n",
            "\u001b[1m3477/3477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 53ms/step - accuracy: 0.7942 - loss: 0.4959 - val_accuracy: 0.7067 - val_loss: 0.7672 - learning_rate: 4.0000e-04\n",
            "Epoch 8/40\n",
            "\u001b[1m3475/3477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8026 - loss: 0.4706[warn] failed /content/drive/My Drive/music_dataset/Beethoven/Anhang 14-3.mid: Could not decode key with 3 flats and mode 255\n",
            "\u001b[1m3477/3477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 53ms/step - accuracy: 0.8026 - loss: 0.4706 - val_accuracy: 0.7531 - val_loss: 0.6172 - learning_rate: 4.0000e-04\n",
            "Epoch 9/40\n",
            "\u001b[1m3475/3477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8145 - loss: 0.4463[warn] failed /content/drive/My Drive/music_dataset/Beethoven/Anhang 14-3.mid: Could not decode key with 3 flats and mode 255\n",
            "\u001b[1m3477/3477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 53ms/step - accuracy: 0.8145 - loss: 0.4463 - val_accuracy: 0.7668 - val_loss: 0.5829 - learning_rate: 4.0000e-04\n",
            "Epoch 10/40\n",
            "\u001b[1m1042/3477\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:03\u001b[0m 51ms/step - accuracy: 0.8159 - loss: 0.4433"
          ]
        }
      ],
      "source": [
        "import os, glob, itertools, math\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pretty_midi\n",
        "from collections import defaultdict, Counter\n",
        "from pathlib import Path\n",
        "\n",
        "# Mounting content from my google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "\n",
        "# ======================\n",
        "# Config (from EDA)\n",
        "# ======================\n",
        "DATA_DIR = \"/content/drive/My Drive/music_dataset\"\n",
        "CLASSES    = [\"Bach\", \"Beethoven\", \"Chopin\", \"Mozart\"]\n",
        "MIDI_EXTS  = [\".mid\", \".midi\"]\n",
        "\n",
        "FS         = 8            # frames/sec for piano roll\n",
        "WIN_SECS   = 10           # window length\n",
        "HOP_SECS   = 5            # hop\n",
        "WIN        = WIN_SECS * FS\n",
        "HOP        = HOP_SECS * FS\n",
        "\n",
        "PITCH_LOW  = 25           # crop inclusive\n",
        "PITCH_HIGH = 100          # crop inclusive\n",
        "PITCHES    = PITCH_HIGH - PITCH_LOW + 1  # = 75\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS     = 40\n",
        "LR         = 4e-4\n",
        "SEED       = 1337\n",
        "\n",
        "rng = np.random.default_rng(SEED)\n",
        "tf.keras.utils.set_random_seed(SEED)\n",
        "\n",
        "\n",
        "def iter_midi_files(root: Path):\n",
        "    # Recursively yield all .mid/.midi (case‑insensitive), skipping hidden dirs\n",
        "    for p in root.rglob(\"*\"):\n",
        "        if p.is_file() and p.suffix.lower() in MIDI_EXTS and not any(part.startswith(\".\") for part in p.parts):\n",
        "            yield str(p)\n",
        "\n",
        "def list_files_recursive(data_dir, classes):\n",
        "    # Ensure it's a Path object\n",
        "    data_dir = Path(data_dir)\n",
        "\n",
        "    files, labels = [], []\n",
        "    for idx, comp in enumerate(classes):\n",
        "        comp_dir = data_dir / comp\n",
        "        if not comp_dir.exists():\n",
        "            print(f\"[warn] missing composer dir: {comp_dir}\")\n",
        "            continue\n",
        "\n",
        "        for file_path in comp_dir.rglob(\"*\"):\n",
        "            if file_path.suffix.lower() in (\".mid\", \".midi\"):\n",
        "                files.append(str(file_path))\n",
        "                labels.append(idx)\n",
        "\n",
        "    return files, labels\n",
        "\n",
        "# ======================\n",
        "# Split (reuse or create)\n",
        "# ======================\n",
        "\n",
        "\n",
        "files, labels = list_files_recursive(DATA_DIR, CLASSES)\n",
        "\n",
        "# Stratified piece-level split (feel free to replace with your saved LSTM split)\n",
        "def make_split(files, labels, val_ratio=0.15, test_ratio=0.15):\n",
        "    by_class = defaultdict(list)\n",
        "    for p, y in zip(files, labels):\n",
        "        by_class[y].append(p)\n",
        "    train, val, test = [], [], []\n",
        "    for y, items in by_class.items():\n",
        "        rng.shuffle(items)\n",
        "        n=len(items); n_test=round(n*test_ratio); n_val=round(n*val_ratio)\n",
        "        test.extend((p,y) for p in items[:n_test])\n",
        "        val .extend((p,y) for p in items[n_test:n_test+n_val])\n",
        "        train.extend((p,y) for p in items[n_test+n_val:])\n",
        "    rng.shuffle(train); rng.shuffle(val); rng.shuffle(test)\n",
        "    return train, val, test\n",
        "\n",
        "train, val, test = make_split(files, labels)\n",
        "print(f\"Pieces -> train: {len(train)}, val: {len(val)}, test: {len(test)}\")\n",
        "\n",
        "# ======================\n",
        "# MIDI -> Piano-roll utils\n",
        "# ======================\n",
        "def midi_to_roll(path, fs=FS):\n",
        "    \"\"\"Return (128, T) binary piano-roll; robust to odd files.\"\"\"\n",
        "    try:\n",
        "        pm = pretty_midi.PrettyMIDI(path)\n",
        "        T = int(np.ceil(pm.get_end_time() * fs)) + 1\n",
        "        roll = np.zeros((128, T), dtype=np.uint8)\n",
        "        for inst in pm.instruments:\n",
        "            for note in inst.notes:\n",
        "                s = max(0, int(np.floor(note.start * fs)))\n",
        "                e = min(T, int(np.ceil(note.end * fs)))\n",
        "                if e > s:\n",
        "                    roll[note.pitch, s:e] = 1\n",
        "        return roll\n",
        "    except Exception as e:\n",
        "        print(f\"[warn] failed {path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def cap_sustain(roll, max_secs=4.0, fs=FS):\n",
        "    \"\"\"Cap continuous '1' runs per pitch to reduce pedal-induced blobs.\"\"\"\n",
        "    max_len = int(max_secs * fs)\n",
        "    R = roll.copy()\n",
        "    for p in range(R.shape[0]):\n",
        "        row = R[p]\n",
        "        i = 0\n",
        "        while i < row.size:\n",
        "            if row[i] == 1:\n",
        "                j = i\n",
        "                while j < row.size and row[j] == 1:\n",
        "                    j += 1\n",
        "                if (j - i) > max_len:\n",
        "                    row[i+max_len:j] = 0\n",
        "                i = j\n",
        "            else:\n",
        "                i += 1\n",
        "    return R\n",
        "\n",
        "def crop_roll(roll, low=PITCH_LOW, high=PITCH_HIGH):\n",
        "    return roll[low:high+1]\n",
        "\n",
        "def window_roll(roll, win=WIN, hop=HOP):\n",
        "    T = roll.shape[1]\n",
        "    if T < win:\n",
        "        pad = np.zeros((roll.shape[0], win - T), dtype=roll.dtype)\n",
        "        return [np.concatenate([roll, pad], axis=1)]\n",
        "    return [roll[:, s:s+win] for s in range(0, T - win + 1, hop)]\n",
        "\n",
        "# ======================\n",
        "# Augmentation (conservative from EDA)\n",
        "# ======================\n",
        "def augment_roll(roll, max_semitones=2, time_scales=(0.9, 1.0, 1.1)):\n",
        "    # pitch shift\n",
        "    st = rng.integers(-max_semitones, max_semitones+1)\n",
        "    aug = roll\n",
        "    if st != 0:\n",
        "        aug = np.roll(aug, shift=st, axis=0)\n",
        "        if st > 0:  aug[:st, :] = 0\n",
        "        else:       aug[st:, :] = 0\n",
        "    # time stretch\n",
        "    scale = rng.choice(time_scales)\n",
        "    if scale != 1.0:\n",
        "        T = aug.shape[1]\n",
        "        new_T = int(round(T * scale))\n",
        "        idx = np.clip((np.arange(new_T) / scale).astype(int), 0, T-1)\n",
        "        aug = aug[:, idx]\n",
        "    return aug\n",
        "\n",
        "def to_input(chunk):\n",
        "    x = chunk.astype(np.float32)  # keep density info\n",
        "    return x[..., None]           # (H, W, 1)\n",
        "\n",
        "# ======================\n",
        "# tf.data pipeline\n",
        "# ======================\n",
        "def gen_examples(pairs, augment=False):\n",
        "    for path, y in pairs:\n",
        "        roll = midi_to_roll(path)\n",
        "        if roll is None:\n",
        "            continue\n",
        "        roll = cap_sustain(roll, max_secs=4.0, fs=FS)\n",
        "        roll = crop_roll(roll)\n",
        "        for ch in window_roll(roll):\n",
        "            if augment:\n",
        "                ch = augment_roll(ch)\n",
        "                # re-fit to exact window after time-stretch\n",
        "                if ch.shape[1] < WIN:\n",
        "                    pad = np.zeros((PITCHES, WIN - ch.shape[1]), dtype=ch.dtype)\n",
        "                    ch = np.concatenate([ch, pad], axis=1)\n",
        "                elif ch.shape[1] > WIN:\n",
        "                    ch = ch[:, :WIN]\n",
        "            yield to_input(ch), y\n",
        "\n",
        "def make_dataset(pairs, shuffle=True, augment=False):\n",
        "    spec = (\n",
        "        tf.TensorSpec(shape=(PITCHES, WIN, 1), dtype=tf.float32),\n",
        "        tf.TensorSpec(shape=(), dtype=tf.int32)\n",
        "    )\n",
        "    ds = tf.data.Dataset.from_generator(lambda: gen_examples(pairs, augment=augment),\n",
        "                                        output_signature=spec)\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(8192, seed=SEED, reshuffle_each_iteration=True)\n",
        "    return ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_ds = make_dataset(train, shuffle=True,  augment=True)\n",
        "val_ds   = make_dataset(val,   shuffle=False, augment=False)\n",
        "test_ds  = make_dataset(test,  shuffle=False, augment=False)\n",
        "\n",
        "# ======================\n",
        "# Class weights from WINDOW COUNTS (post-slicing)\n",
        "# ======================\n",
        "def count_windows(pairs):\n",
        "    counts = Counter()\n",
        "    for path, y in pairs:\n",
        "        roll = midi_to_roll(path)\n",
        "        if roll is None:\n",
        "            continue\n",
        "        n = len(window_roll(crop_roll(cap_sustain(roll))))\n",
        "        counts[y] += n\n",
        "    return counts\n",
        "\n",
        "win_counts = count_windows(train)\n",
        "total = sum(win_counts.values())\n",
        "class_weight = {}\n",
        "for k in range(len(CLASSES)):\n",
        "    # inverse frequency\n",
        "    freq = win_counts.get(k, 1)\n",
        "    class_weight[k] = total / (len(CLASSES) * freq)\n",
        "print(\"Window counts per class:\", {CLASSES[k]: v for k, v in win_counts.items()})\n",
        "print(\"Class weights:\", {CLASSES[k]: round(v, 3) for k, v in class_weight.items()})\n",
        "\n",
        "# ======================\n",
        "# CNN (EDA-informed: mixed kernels, dropout, BN)\n",
        "# ======================\n",
        "def build_cnn(input_shape=(PITCHES, WIN, 1), num_classes=len(CLASSES)):\n",
        "    inp = keras.layers.Input(shape=input_shape)\n",
        "    x = inp\n",
        "\n",
        "    # Block 1: small textures\n",
        "    x = keras.layers.Conv2D(32, (3,3), padding=\"same\", activation=\"relu\")(x)\n",
        "    x = keras.layers.BatchNormalization()(x)\n",
        "    x = keras.layers.Conv2D(32, (3,3), padding=\"same\", activation=\"relu\")(x)\n",
        "    x = keras.layers.BatchNormalization()(x)\n",
        "    x = keras.layers.MaxPooling2D((2,2))(x)         # H/2, W/2\n",
        "    x = keras.layers.Dropout(0.2)(x)\n",
        "\n",
        "    # Block 2: widen features\n",
        "    x = keras.layers.Conv2D(64, (3,3), padding=\"same\", activation=\"relu\")(x)\n",
        "    x = keras.layers.BatchNormalization()(x)\n",
        "    x = keras.layers.Conv2D(64, (5,3), padding=\"same\", activation=\"relu\")(x)  # slightly taller\n",
        "    x = keras.layers.BatchNormalization()(x)\n",
        "    x = keras.layers.MaxPooling2D((2,2))(x)         # H/4, W/4\n",
        "    x = keras.layers.Dropout(0.25)(x)\n",
        "\n",
        "    # Block 3: capture large leaps / thick chords\n",
        "    x = keras.layers.Conv2D(128, (7,3), padding=\"same\", activation=\"relu\")(x) # tall kernel\n",
        "    x = keras.layers.BatchNormalization()(x)\n",
        "    x = keras.layers.Conv2D(128, (3,3), padding=\"same\", activation=\"relu\")(x)\n",
        "    x = keras.layers.BatchNormalization()(x)\n",
        "    x = keras.layers.MaxPooling2D((2,2))(x)         # H/8, W/8\n",
        "    x = keras.layers.Dropout(0.3)(x)\n",
        "\n",
        "    # Head\n",
        "    x = keras.layers.Conv2D(256, (3,3), padding=\"same\", activation=\"relu\")(x)\n",
        "    x = keras.layers.BatchNormalization()(x)\n",
        "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "    x = keras.layers.Dropout(0.4)(x)\n",
        "    x = keras.layers.Dense(128, activation=\"relu\")(x)\n",
        "    x = keras.layers.BatchNormalization()(x)\n",
        "    x = keras.layers.Dropout(0.35)(x)\n",
        "    out = keras.layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "    model = keras.Model(inp, out)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(LR),\n",
        "                  loss=\"sparse_categorical_crossentropy\",\n",
        "                  metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "model = build_cnn()\n",
        "model.summary()\n",
        "\n",
        "# ======================\n",
        "# Train\n",
        "# ======================\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_accuracy\", factor=0.5, patience=4, min_lr=1e-5, verbose=1),\n",
        "    tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=8, restore_best_weights=True, verbose=1)\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=EPOCHS,\n",
        "    class_weight=class_weight,\n",
        "    callbacks=callbacks\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model tunning**"
      ],
      "metadata": {
        "id": "PQgyyS2UpaMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob, itertools, math\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pretty_midi\n",
        "from collections import defaultdict, Counter\n",
        "from pathlib import Path\n",
        "\n",
        "# Mounting content from my google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "\n",
        "# ======================\n",
        "# Config (from EDA)\n",
        "# ======================\n",
        "DATA_DIR = \"/content/drive/My Drive/music_dataset\"\n",
        "CLASSES    = [\"Bach\", \"Beethoven\", \"Chopin\", \"Mozart\"]\n",
        "MIDI_EXTS  = [\".mid\", \".midi\"]\n",
        "\n",
        "FS         = 8            # frames/sec for piano roll\n",
        "WIN_SECS   = 10           # window length\n",
        "HOP_SECS   = 5            # hop\n",
        "WIN        = WIN_SECS * FS\n",
        "HOP        = HOP_SECS * FS\n",
        "\n",
        "PITCH_LOW  = 25           # crop inclusive\n",
        "PITCH_HIGH = 100          # crop inclusive\n",
        "PITCHES    = PITCH_HIGH - PITCH_LOW + 1  # = 75\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS     = 40\n",
        "LR         = 4e-4\n",
        "SEED       = 1337\n",
        "\n",
        "rng = np.random.default_rng(SEED)\n",
        "tf.keras.utils.set_random_seed(SEED)\n",
        "\n",
        "\n",
        "def iter_midi_files(root: Path):\n",
        "    # Recursively yield all .mid/.midi (case‑insensitive), skipping hidden dirs\n",
        "    for p in root.rglob(\"*\"):\n",
        "        if p.is_file() and p.suffix.lower() in MIDI_EXTS and not any(part.startswith(\".\") for part in p.parts):\n",
        "            yield str(p)\n",
        "\n",
        "def list_files_recursive(data_dir, classes):\n",
        "    # Ensure it's a Path object\n",
        "    data_dir = Path(data_dir)\n",
        "\n",
        "    files, labels = [], []\n",
        "    for idx, comp in enumerate(classes):\n",
        "        comp_dir = data_dir / comp\n",
        "        if not comp_dir.exists():\n",
        "            print(f\"[warn] missing composer dir: {comp_dir}\")\n",
        "            continue\n",
        "\n",
        "        for file_path in comp_dir.rglob(\"*\"):\n",
        "            if file_path.suffix.lower() in (\".mid\", \".midi\"):\n",
        "                files.append(str(file_path))\n",
        "                labels.append(idx)\n",
        "\n",
        "    return files, labels\n",
        "\n",
        "# ======================\n",
        "# Split (reuse or create)\n",
        "# ======================\n",
        "\n",
        "\n",
        "files, labels = list_files_recursive(DATA_DIR, CLASSES)\n",
        "\n",
        "# Stratified piece-level split (feel free to replace with your saved LSTM split)\n",
        "def make_split(files, labels, val_ratio=0.15, test_ratio=0.15):\n",
        "    by_class = defaultdict(list)\n",
        "    for p, y in zip(files, labels):\n",
        "        by_class[y].append(p)\n",
        "    train, val, test = [], [], []\n",
        "    for y, items in by_class.items():\n",
        "        rng.shuffle(items)\n",
        "        n=len(items); n_test=round(n*test_ratio); n_val=round(n*val_ratio)\n",
        "        test.extend((p,y) for p in items[:n_test])\n",
        "        val .extend((p,y) for p in items[n_test:n_test+n_val])\n",
        "        train.extend((p,y) for p in items[n_test+n_val:])\n",
        "    rng.shuffle(train); rng.shuffle(val); rng.shuffle(test)\n",
        "    return train, val, test\n",
        "\n",
        "train, val, test = make_split(files, labels)\n",
        "print(f\"Pieces -> train: {len(train)}, val: {len(val)}, test: {len(test)}\")\n",
        "\n",
        "\n",
        "# --- Multi-channel MIDI loader ---\n",
        "def midi_to_roll_multich(path, fs=FS):\n",
        "    try:\n",
        "        pm = pretty_midi.PrettyMIDI(path)\n",
        "        T = int(np.ceil(pm.get_end_time() * fs)) + 1\n",
        "        on = np.zeros((128, T), dtype=np.float32)\n",
        "        vel = np.zeros((128, T), dtype=np.float32)\n",
        "        for inst in pm.instruments:\n",
        "            for note in inst.notes:\n",
        "                s = max(0, int(np.floor(note.start * fs)))\n",
        "                e = min(T, int(np.ceil(note.end * fs)))\n",
        "                on[note.pitch, s:e] = 1.0\n",
        "                vel[note.pitch, s:e] = max(vel[note.pitch, s:e].max(), note.velocity / 127.0)\n",
        "        onset = np.zeros_like(on)\n",
        "        onset[:, 1:] = np.maximum(0.0, on[:, 1:] - on[:, :-1])\n",
        "        return on, vel, onset\n",
        "    except Exception as e:\n",
        "        print(f\"[warn] failed {path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# --- Multi-channel input stacker ---\n",
        "def to_input_multich(on, vel, onset):\n",
        "    return np.stack([on, vel, onset], axis=-1)  # (H, W, 3)\n",
        "\n",
        "# --- Balanced training dataset generator ---\n",
        "STEPS_PER_CLASS = 1200  # tune as needed\n",
        "\n",
        "def balanced_train_ds_multich(pairs):\n",
        "    per_class = {k: [] for k in range(len(CLASSES))}\n",
        "    for path, y in pairs:\n",
        "        per_class[y].append(path)\n",
        "    for k in per_class:\n",
        "        rng.shuffle(per_class[k])\n",
        "\n",
        "    def gen():\n",
        "        counts = {k: 0 for k in per_class}\n",
        "        iters = {k: iter(per_class[k]) for k in per_class}\n",
        "        while min(counts.values()) < STEPS_PER_CLASS:\n",
        "            for k in per_class:\n",
        "                if counts[k] >= STEPS_PER_CLASS:\n",
        "                    continue\n",
        "                try:\n",
        "                    p = next(iters[k])\n",
        "                except StopIteration:\n",
        "                    continue\n",
        "                m = midi_to_roll_multich(p)\n",
        "                if m is None:\n",
        "                    continue\n",
        "                on, vel, onset = m\n",
        "                on = crop_roll(cap_sustain(on))\n",
        "                vel = crop_roll(cap_sustain(vel))\n",
        "                onset = crop_roll(cap_sustain(onset))\n",
        "                on_windows = window_roll(on)\n",
        "                vel_windows = window_roll(vel)\n",
        "                onset_windows = window_roll(onset)\n",
        "                for chunk_on, chunk_vel, chunk_onset in zip(on_windows, vel_windows, onset_windows):\n",
        "                    yield to_input_multich(chunk_on, chunk_vel, chunk_onset), k\n",
        "                    counts[k] += 1\n",
        "                    if counts[k] >= STEPS_PER_CLASS:\n",
        "                        break\n",
        "\n",
        "    spec = (tf.TensorSpec((PITCHES, WIN, 3), tf.float32),\n",
        "            tf.TensorSpec((), tf.int32))\n",
        "    return tf.data.Dataset.from_generator(gen, output_signature=spec).shuffle(8192).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# --- Standard dataset generator for val/test ---\n",
        "def gen_examples_multich(pairs, augment=False):\n",
        "    for path, y in pairs:\n",
        "        m = midi_to_roll_multich(path)\n",
        "        if m is None:\n",
        "            continue\n",
        "        on, vel, onset = m\n",
        "        on = cap_sustain(on)\n",
        "        vel = cap_sustain(vel)\n",
        "        onset = cap_sustain(onset)\n",
        "\n",
        "        on = crop_roll(on)\n",
        "        vel = crop_roll(vel)\n",
        "        onset = crop_roll(onset)\n",
        "\n",
        "        on_windows = window_roll(on)\n",
        "        vel_windows = window_roll(vel)\n",
        "        onset_windows = window_roll(onset)\n",
        "\n",
        "        for chunk_on, chunk_vel, chunk_onset in zip(on_windows, vel_windows, onset_windows):\n",
        "            if augment:\n",
        "                # Optional augmentation code here (same as before) if you want\n",
        "                pass\n",
        "            yield to_input_multich(chunk_on, chunk_vel, chunk_onset), y\n",
        "\n",
        "def make_dataset_multich(pairs, shuffle=True, augment=False):\n",
        "    spec = (\n",
        "        tf.TensorSpec(shape=(PITCHES, WIN, 3), dtype=tf.float32),\n",
        "        tf.TensorSpec(shape=(), dtype=tf.int32)\n",
        "    )\n",
        "    ds = tf.data.Dataset.from_generator(lambda: gen_examples_multich(pairs, augment=augment),\n",
        "                                        output_signature=spec)\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(8192, seed=SEED, reshuffle_each_iteration=True)\n",
        "    return ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# --- Create datasets ---\n",
        "train_ds = balanced_train_ds_multich(train)\n",
        "val_ds   = make_dataset_multich(val, shuffle=False, augment=False)\n",
        "test_ds  = make_dataset_multich(test, shuffle=False, augment=False)\n",
        "\n",
        "# --- Build model with updated input shape ---\n",
        "model = build_cnn(input_shape=(PITCHES, WIN, 3))\n",
        "model.summary()\n",
        "\n",
        "# --- Train without class weights ---\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=callbacks\n",
        ")\n"
      ],
      "metadata": {
        "id": "FZnBBWbjo2Uu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}